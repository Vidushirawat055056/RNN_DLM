{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtfG2265a6Vb"
      },
      "source": [
        "# Reviews Sentiment analysis using Recurrent Neural Network\n",
        "\n",
        "\n",
        "Contributors:\n",
        "- Sejal Raj (055041)\n",
        "- Vidushi Rawat (055056)\n",
        "\n",
        "---\n",
        "## Objective\n",
        "\n",
        "To design, implement, and evaluate a deep learning-based sentiment analysis model using RNN architecture. This model aims to classify movie reviews based on sentiment by leveraging the sequential patterns present in text data.\n",
        "\n",
        "---\n",
        "\n",
        "## Problem Statement\n",
        "\n",
        "- Online movie reviews significantly influence public opinion.\n",
        "- Classifying sentiment is challenging due to language complexity.\n",
        "- The goal is to develop a machine learning model for sentiment analysis.\n",
        "- An RNN-based approach will be used to capture contextual information.\n",
        "- The model will classify reviews as positive, negative, or neutral.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Tasks\n",
        "\n",
        "### 1. Data Preprocessing\n",
        "\n",
        "The data preprocessing stage prepares the movie review dataset to ensure compatibility with the RNN model. The key steps are:\n",
        "\n",
        "#### **I) Sentiment Encoding**\n",
        "- Positive Sentiment → Encoded as **1**\n",
        "- Negative Sentiment → Encoded as **0**\n",
        "\n",
        "#### **II) Text Normalization**\n",
        "- **Removing Special Characters:** Stripping unnecessary characters (e.g., punctuation, special symbols) to clean the text.\n",
        "- **Lowercasing:** Converting all reviews to lowercase for uniformity and consistency.\n",
        "\n",
        "#### **III) Tokenization**\n",
        "- Splitting the text into individual tokens (words).\n",
        "- Using a vocabulary size of **20,000** most frequent words (`max_features=20000`). Any words outside this range are replaced with a placeholder token.\n",
        "\n",
        "#### **IV) Sequence Padding**\n",
        "- Ensuring all tokenized reviews are of the same length by:\n",
        "  - Padding shorter sequences with zeros at the beginning or end.\n",
        "  - Truncating longer sequences to a maximum length of **400** tokens (`max_length = 400`).\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Model Development\n",
        "\n",
        "To build a model that classifies movie reviews as positive or negative, we follow these steps:\n",
        "\n",
        "#### **I) Using the Data**\n",
        "\n",
        "**Training Data:**\n",
        "- The training data consists of **50,000** records with the following **2 columns**:\n",
        "  - **Reviews:** The textual review of the movie.\n",
        "  - **Sentiment:** The sentiment label (positive or negative).\n",
        "- A random sample of **40,000** reviews is selected using a random state of **5504156** to ensure reproducibility.\n",
        "\n",
        "**Dataset link:** https://drive.google.com/file/d/1KfrPoxKu_7pFKnuSLYmBCB2-U4QDpV5g/view?usp=sharing\n",
        "\n",
        "**Testing Data:**\n",
        "- The testing data consists of **151** records with the following **4 columns**:\n",
        "  - **Movie Name:** The title of the movie.\n",
        "  - **Rating:** The rating given to the movie.\n",
        "  - **Reviews:** The textual review of the movie.\n",
        "  - **Sentiment:** The sentiment label (positive or negative).\n",
        "- This dataset was created by manually scraping the data on reviews and ratings of various movies from **Metacritic**.\n",
        "**Dataset Link :** https://drive.google.com/file/d/1mDdWS7qsze_M0gDnstnv1Mm1vaudA2Q-/view?usp=drive_link\n",
        "\n",
        "\n",
        "#### **II) Model Structure**\n",
        "\n",
        "The model is built step by step with these layers:\n",
        " **Model link:** https://drive.google.com/file/d/1so6p0WIAbKXe7yV3cQITIwyuWetHOaHu/view?usp=sharing\n",
        "  \n",
        "##### **Embedding Layer**\n",
        "- **Input dimension:** 20,000 (vocabulary size)\n",
        "- **Output dimension:** 128 (word embedding size)\n",
        "- **Input length:** 400 (maximum sequence length)\n",
        "\n",
        "##### **Recurrent Layer**\n",
        "- **Type:** SimpleRNN\n",
        "- **Number of units:** 64\n",
        "- **Activation function:** Tanh\n",
        "- **Return sequences:** False (since it’s a single RNN layer)\n",
        "- **Regularization:** Dropout (0.2) to prevent overfitting\n",
        "\n",
        "##### **Fully Connected Layer**\n",
        "- **Type:** Dense layer\n",
        "- **Number of neurons:** 1\n",
        "- **Activation function:** Sigmoid (for binary classification)\n",
        "\n",
        "#### **III) Training the Model**\n",
        "\n",
        "The model is trained on IMDB reviews by splitting the sampled dataset of **40,000** reviews into **80%** for training and **20%** for testing, ensuring the model learns effectively while being evaluated on unseen data during training.\n",
        "\n",
        "**Model Compilation and Training:**\n",
        "\n",
        "- **Loss Function:** Binary Crossentropy (suitable for binary classification)\n",
        "- **Optimizer:** Adam (learning rate = 0.001)\n",
        "- **Batch Size:** 32\n",
        "- **Epochs:** 15 (With early stopping)\n",
        "\n",
        "**Early Stopping Criteria:**\n",
        "- **Monitored metric:** Validation Loss\n",
        "- **Patience:** 3 epochs\n",
        "- **Best weights restored** if validation loss does not improve\n",
        "- The model was trained for **10** epochs initially and then for an additional **5** epochs.\n",
        "\n",
        "#### **IV) Testing the Model with Metacritic Data**\n",
        "- After training on IMDB reviews, the model is tested on the **100 manually collected Metacritic reviews**.\n",
        "- Performed data preprocessing, tokenization, and sequence padding as performed with the training dataset.\n",
        "\n",
        "#### **V) Predicting Sentiment for New Reviews**\n",
        "Once trained, the model can predict whether new reviews are **positive or negative**.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Observations\n",
        "\n",
        "- **Training accuracy** increased steadily, reaching approximately **90%** after **10 epochs**.\n",
        "- **Validation accuracy** remained stable at around **86.47%**, indicating good generalization.\n",
        "- The final **test accuracy** on the IMDB test set was around **86%**, suggesting a well-trained model with slight room for improvement.\n",
        "- Training loss started to decrease significantly with every epoch, with potential signs of overfitting mitigated by **early stopping and dropout**.\n",
        "- The model performed similarly on the Metacritic dataset, achieving a **test accuracy of approximately 72%**, showing that it generalizes well across different review datasets but could improve if **LSTM was used instead of RNN**.\n",
        "- Early stopping was triggered after a few epochs in both training phases, preventing overfitting and ensuring that the best model was retained.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Managerial Insights\n",
        "\n",
        "### **Model Effectiveness & Business Implications**\n",
        "- The RNN model performs well on the IMDB dataset but generalizes **poorly** on Metacritic reviews.\n",
        "- This suggests that Metacritic reviews might have **different writing styles, slang, or review structures** compared to IMDB.\n",
        "\n",
        "### **Improvement Areas**\n",
        "- **Better Preprocessing:** Introduce techniques like stemming, lemmatization, stop-word removal, and n-grams to improve accuracy.\n",
        "- **More Complex Architectures:** RNNs have limited long-term memory; switching to **LSTMs** may enhance generalization.\n",
        "- **Larger Dataset & Augmentation:** Training on a combined dataset of IMDB and Metacritic reviews may improve model robustness.\n",
        "- **Domain Adaptation:** Fine-tuning the model specifically on Metacritic reviews could improve cross-domain accuracy.\n",
        "\n",
        "### **Business Applications**\n",
        "- **Customer Sentiment Monitoring:** Companies can use this model to analyze movie, product, or service reviews to gauge public opinion.\n",
        "- **Brand Reputation Analysis:** Identifying sentiment trends can help businesses manage PR crises and improve customer engagement.\n",
        "- **Automated Review Filtering:** Businesses can filter out fake reviews or spam using an improved sentiment classification model.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Conclusion & Recommendations\n",
        "\n",
        "### **Immediate Steps:**\n",
        "- Improve text preprocessing by handling stop words and using TF-IDF weights.\n",
        "- Fine-tune the model using **transfer learning** with additional datasets.\n",
        "- Consider switching to **LSTM/GRU-based models** for improved generalization.\n",
        "\n",
        "### **Long-Term Strategy:**\n",
        "- Expand training data by incorporating reviews from multiple platforms.\n",
        "- Implement **real-time sentiment tracking** in a dashboard for actionable insights.\n",
        "- Conduct **A/B testing** with different architectures to find the best-performing model.\n",
        "\n",
        "By implementing these recommendations, the sentiment analysis model can achieve **higher accuracy (target: 75%+)** and be effectively deployed for business use cases.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8FnQSZINZaI"
      },
      "source": [
        "## 1. Importing the Libraries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "w0cZz5681Pmg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "V9XDI9fmFVaF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4b9d607-c2ee-4535-81c8-093ed1773508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding,Dropout\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj3rB7p0N2T5"
      },
      "source": [
        "## 2. Preparing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gRBUPqTFzAp",
        "outputId": "5ccd1515-e3fc-4d1b-aafb-dfb2951d273d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in the dataset:\n",
            "['review', 'sentiment']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "srr4156_data1 = pd.read_csv('IMDB Dataset.csv')\n",
        "print(\"Columns in the dataset:\")\n",
        "print(srr4156_data1.columns.tolist())\n",
        "srr4156_data1.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI4LIHSgFxnZ"
      },
      "source": [
        "### 2.1 Creating a random state of 40000 records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0HTtZLNoHCeg"
      },
      "outputs": [],
      "source": [
        "srr4156_data = srr4156_data1.sample(n=40000, random_state=5504156)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjG-_V6lOaVd"
      },
      "source": [
        "### 2.2 Data cleaning and pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u_NGDMjtGB9U"
      },
      "outputs": [],
      "source": [
        "srr4156_data[\"review\"] = srr4156_data[\"review\"].str.lower()\n",
        "srr4156_data[\"review\"] = srr4156_data[\"review\"].replace(r'[^a-z0-9\\s]', '', regex=True)\n",
        "\n",
        "srr4156_data['sentiment value'] = srr4156_data['sentiment'].apply(lambda x: 1 if x== \"positive\" else 0)\n",
        "srr4156_data = srr4156_data.dropna()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSUuitILO07u"
      },
      "source": [
        "### 2.3 Tokenizing and Padding of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FRGPp12dGKcw"
      },
      "outputs": [],
      "source": [
        "srr4156_max_features = 20000\n",
        "srr4156_max_length =400\n",
        "\n",
        "tokenizer = Tokenizer(num_words=srr4156_max_features)\n",
        "tokenizer.fit_on_texts(srr4156_data[\"review\"])\n",
        "X = pad_sequences(tokenizer.texts_to_sequences(srr4156_data[\"review\"]), maxlen=srr4156_max_length)\n",
        "y = srr4156_data['sentiment value'].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJSO3IOCPCWL"
      },
      "source": [
        "### 2.4 Spliting of dataset into test, train and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gKsc41H0GZw_"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.1, random_state=42, stratify=y_train\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4NsCCTXPmmF"
      },
      "source": [
        "## 3. Model Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf3xkbtmG4VH",
        "outputId": "ce7fd575-8a35-420a-da74-d5af7431ebad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "srr4156_model1 = Sequential([\n",
        "    Embedding(input_dim=srr4156_max_features, output_dim=128, input_length=srr4156_max_length),\n",
        "    SimpleRNN(64, activation='tanh', return_sequences=False),\n",
        "    Dense(1, activation='sigmoid'),\n",
        "    Dropout(0.2),  # Helps prevent overfitting\n",
        "])\n",
        "\n",
        "srr4156_model1.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNH_mgUwf2F8"
      },
      "source": [
        "### 3.1 Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fn-gYk0RsPc",
        "outputId": "b5435918-b628-4406-a020-2fbda36e3e71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 7 Complete [00h 01m 57s]\n",
            "val_accuracy: 0.840624988079071\n",
            "\n",
            "Best val_accuracy So Far: 0.8581249713897705\n",
            "Total elapsed time: 00h 16m 11s\n",
            "\n",
            "Search: Running Trial #8\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "64                |256               |embedding_dim\n",
            "32                |64                |rnn_units\n",
            "0.5               |0.5               |dropout_1\n",
            "64                |64                |rnn_units_2\n",
            "0.2               |0.2               |dropout_2\n",
            "0.001             |0.0005            |learning_rate\n",
            "2                 |2                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "2                 |2                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n",
            "Epoch 1/2\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 57ms/step - accuracy: 0.5852 - loss: 0.6560 - val_accuracy: 0.6281 - val_loss: 0.6520\n",
            "Epoch 2/2\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 55ms/step - accuracy: 0.7669 - loss: 0.4758 - val_accuracy: 0.7575 - val_loss: 0.5381\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_tuner\n",
        "import keras_tuner as kt\n",
        "def build_model(hp):\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=srr4156_max_features, output_dim=hp.Choice('embedding_dim', [64, 128, 256]), input_length=srr4156_max_length),\n",
        "        SimpleRNN(hp.Choice('rnn_units', [32, 64, 128]), return_sequences=True),\n",
        "        Dropout(hp.Choice('dropout_1', [0.2, 0.3, 0.5])),\n",
        "        SimpleRNN(hp.Choice('rnn_units_2', [32, 64]), return_sequences=False),\n",
        "        Dropout(hp.Choice('dropout_2', [0.2, 0.3, 0.5])),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=Adam(learning_rate=hp.Choice('learning_rate', [0.001, 0.0005, 0.0001])),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Hyperparameter tuning\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    directory='tuner_dir',\n",
        "    project_name='sentiment_analysis'\n",
        ")\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val), batch_size=32)\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUYeTTYzPwol"
      },
      "source": [
        "### 3.2 Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQkDdZS6H1ca",
        "outputId": "62e0e8b1-c0bf-408f-9c4d-68dd189ad613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 30ms/step - accuracy: 0.5207 - loss: 2.1420 - val_accuracy: 0.5431 - val_loss: 0.6700\n",
            "Epoch 2/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 29ms/step - accuracy: 0.6755 - loss: 2.0858 - val_accuracy: 0.8022 - val_loss: 0.4620\n",
            "Epoch 3/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 30ms/step - accuracy: 0.7906 - loss: 1.8942 - val_accuracy: 0.8416 - val_loss: 0.3886\n",
            "Epoch 4/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 29ms/step - accuracy: 0.8371 - loss: 1.7961 - val_accuracy: 0.8019 - val_loss: 0.4342\n",
            "Epoch 5/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 30ms/step - accuracy: 0.8479 - loss: 1.7439 - val_accuracy: 0.8506 - val_loss: 0.3599\n",
            "Epoch 6/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 31ms/step - accuracy: 0.8763 - loss: 1.6917 - val_accuracy: 0.8572 - val_loss: 0.3541\n",
            "Epoch 7/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 29ms/step - accuracy: 0.8822 - loss: 1.7278 - val_accuracy: 0.8619 - val_loss: 0.3378\n",
            "Epoch 8/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 29ms/step - accuracy: 0.8876 - loss: 1.7350 - val_accuracy: 0.8566 - val_loss: 0.3476\n",
            "Epoch 9/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 30ms/step - accuracy: 0.8945 - loss: 1.6612 - val_accuracy: 0.8606 - val_loss: 0.3600\n",
            "Epoch 10/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 29ms/step - accuracy: 0.9004 - loss: 1.5928 - val_accuracy: 0.8647 - val_loss: 0.3630\n",
            "Test accuracy: 0.86\n"
          ]
        }
      ],
      "source": [
        "# commenting this since the model has been trained and saved\n",
        "srr4156_early_stopping = EarlyStopping(\n",
        "    monitor='val_loss', patience=3, restore_best_weights=True\n",
        ")\n",
        "\n",
        "srr4156_history11 = srr4156_model1.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[srr4156_early_stopping],  # Stops if validation loss doesn't improve\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "srr4156_score = srr4156_model1.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test accuracy: {srr4156_score[1]:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "F0JQK6ue9AXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be5bc8b5-d9a5-421d-e467-c167756d09d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 30ms/step - accuracy: 0.8884 - loss: 1.7167 - val_accuracy: 0.8606 - val_loss: 0.3494\n",
            "Epoch 2/5\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 30ms/step - accuracy: 0.8955 - loss: 1.6441 - val_accuracy: 0.8562 - val_loss: 0.3965\n",
            "Epoch 3/5\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 29ms/step - accuracy: 0.8899 - loss: 1.6528 - val_accuracy: 0.8541 - val_loss: 0.3809\n",
            "Epoch 4/5\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 29ms/step - accuracy: 0.8986 - loss: 1.6305 - val_accuracy: 0.8525 - val_loss: 0.4038\n"
          ]
        }
      ],
      "source": [
        "# commenting this since the model has been trained and saved\n",
        "# #running code for 5 more epochs\n",
        "srr4156_history1 = srr4156_model1.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[srr4156_early_stopping],  # Stops if validation loss doesn't improve\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# srr4156_score = srr4156_model1.evaluate(X_test, y_test, verbose=0)\n",
        "# print(f\"Test accuracy: {srr4156_score[1]:.2f}\")\n",
        "# this accuracy is on the test data of IMDB Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6MdZpDfASgx8"
      },
      "outputs": [],
      "source": [
        "srr4156_model1.save('srr4156_model12.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UpH7nV4QOHm"
      },
      "source": [
        "## 4. Loading Metacritic dataset for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kJltGW7J_zDp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "d41b12fc-b930-482d-bb88-0c9bb6c911a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in the dataset:\n",
            "['Movie Name', 'Rating', 'Review', 'sentiment']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Movie Name  Rating                                             Review  \\\n",
              "0  La La Land      10  Damien Chazelles La La Land is a dazzling rom...   \n",
              "1  La La Land      10  The song \"City of Stars\" as a duet encapsulate...   \n",
              "2  La La Land       6  \"La La Land\" does combine Chazelle's fun camer...   \n",
              "3  La La Land       3  I found this movie to be an insult to jazz. Th...   \n",
              "4  La La Land       3  I didn't like the story much. It has some good...   \n",
              "5  La La Land       9  ... what have I done... I can never unsee this...   \n",
              "6  La La Land      10  Damien Chazelle has created another beautiful ...   \n",
              "7  La La Land      10  I mean, it's just perfect. The musics, the sto...   \n",
              "8  La La Land      10  Another musical masterpiece by chazelle, amazi...   \n",
              "9   Pinnochio       6  okay young Disney even though this bombed this...   \n",
              "\n",
              "  sentiment  \n",
              "0  positive  \n",
              "1  positive  \n",
              "2  positive  \n",
              "3  negative  \n",
              "4  negative  \n",
              "5  positive  \n",
              "6  positive  \n",
              "7  positive  \n",
              "8  positive  \n",
              "9  positive  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70f4618c-8ea1-4445-a9fc-7e49eced8c2d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Movie Name</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>La La Land</td>\n",
              "      <td>10</td>\n",
              "      <td>Damien Chazelles La La Land is a dazzling rom...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>La La Land</td>\n",
              "      <td>10</td>\n",
              "      <td>The song \"City of Stars\" as a duet encapsulate...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La La Land</td>\n",
              "      <td>6</td>\n",
              "      <td>\"La La Land\" does combine Chazelle's fun camer...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>La La Land</td>\n",
              "      <td>3</td>\n",
              "      <td>I found this movie to be an insult to jazz. Th...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>La La Land</td>\n",
              "      <td>3</td>\n",
              "      <td>I didn't like the story much. It has some good...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>La La Land</td>\n",
              "      <td>9</td>\n",
              "      <td>... what have I done... I can never unsee this...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>La La Land</td>\n",
              "      <td>10</td>\n",
              "      <td>Damien Chazelle has created another beautiful ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>La La Land</td>\n",
              "      <td>10</td>\n",
              "      <td>I mean, it's just perfect. The musics, the sto...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>La La Land</td>\n",
              "      <td>10</td>\n",
              "      <td>Another musical masterpiece by chazelle, amazi...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Pinnochio</td>\n",
              "      <td>6</td>\n",
              "      <td>okay young Disney even though this bombed this...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70f4618c-8ea1-4445-a9fc-7e49eced8c2d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-70f4618c-8ea1-4445-a9fc-7e49eced8c2d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-70f4618c-8ea1-4445-a9fc-7e49eced8c2d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e1c67c6b-57ee-47b8-a3fd-e2ba673ee9c6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e1c67c6b-57ee-47b8-a3fd-e2ba673ee9c6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e1c67c6b-57ee-47b8-a3fd-e2ba673ee9c6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "srr4156_test_data1",
              "summary": "{\n  \"name\": \"srr4156_test_data1\",\n  \"rows\": 124,\n  \"fields\": [\n    {\n      \"column\": \"Movie Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"Harry Potter 7\",\n          \"Harry Potter 15\",\n          \"La La Land\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0,\n          10,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 119,\n        \"samples\": [\n          \"this movie **** to be honest the acting got really bad and it honestly needed to only be about 1hr 30 minutes instead of 3 hours the only reason it got hyped to high hell is cause infinity war ended on a cliffhanger\",\n          \"I think the only and biggest thing that's bad about this movie is the script. Compared to the first movie, the character motivations (especially our antagonist) are very weak. It is hard to know why the characters do what they do. We keep watching scenes of kidnapping and rescue. The visuals and Zoe Saldana as Neytiri are the biggest things that carry the movie to 6 points.\",\n          \"I didn't like the story much. It has some good moments but not a lot. What the hell was I watching? Very overrated movie. I put off seeing it as I'm not really into musicals. I had to force myself to watch it all the way through and now I feel worse for having seen it. Universal acclaim, man, your opinion may differ.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "srr4156_test_data1 = pd.read_csv('metacritic test dataset22.csv', encoding='latin1')\n",
        "print(\"Columns in the dataset:\")\n",
        "print(srr4156_test_data1.columns.tolist())\n",
        "srr4156_test_data1.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du5dsJDyQfWF"
      },
      "source": [
        "### 4.1 Data cleaning and pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "89gI0p3D-kqi"
      },
      "outputs": [],
      "source": [
        "srr4156_test_data1[\"Review\"] = srr4156_test_data1[\"Review\"].str.lower()\n",
        "srr4156_test_data1[\"Review\"] = srr4156_test_data1[\"Review\"].replace(r'[^a-z0-9\\s]', '', regex=True)\n",
        "\n",
        "srr4156_test_data1['sentiment value'] = srr4156_test_data1['sentiment'].apply(lambda x: 1 if x== \"positive\" else 0)\n",
        "srr4156_test_data1 = srr4156_test_data1.dropna()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6zTuoh9Qj7X"
      },
      "source": [
        "### 4.2 Tokenizing and padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "g4QHVBbC-3mK"
      },
      "outputs": [],
      "source": [
        "\n",
        "# tokenizer = Tokenizer(num_words=20000)\n",
        "# tokenizer.fit_on_texts(srr4156_test_data1[\"Review\"])\n",
        "X = pad_sequences(tokenizer.texts_to_sequences(srr4156_test_data1[\"Review\"]), maxlen=srr4156_max_length)\n",
        "y = srr4156_test_data1['sentiment value'].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfndDy9EQv0r"
      },
      "source": [
        "## 4.3 Accuracy on Metacritic test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "73ic31uJCiSu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b21e9b2d-83a5-4790-eb95-e0acb92f9031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.72\n"
          ]
        }
      ],
      "source": [
        "\n",
        "score = srr4156_model1.evaluate(X, y, verbose=0)\n",
        "print(f\"Test accuracy: {score[1]:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jj3wBm7u9XN3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}